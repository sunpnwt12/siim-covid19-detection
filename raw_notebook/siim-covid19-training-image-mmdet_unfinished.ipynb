{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# !pip install effdet\n# !pip install timm\n!pip install python-gdcm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Library","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport pydicom as dicom\nfrom glob import glob\nimport random\nfrom numba import jit\n\nimport ast\nimport cv2\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\nimport albumentations as A\nfrom albumentations.pytorch.transforms import ToTensorV2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\n# from torch.utils.data import DataLoader, Dataset, random_split\n# from torch.cuda.amp import GradScaler, autocast\n\nimport torchvision\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import average_precision_score\n# from sklearn.metrics import roc_auc_score\n\nimport matplotlib.pyplot as plt\nimport matplotlib\n\nimport os\nimport warnings\nfrom datetime import datetime, timedelta\nimport time\nimport gc\nimport re\nfrom tqdm.notebook import tqdm\nfrom fastprogress.fastprogress import master_bar, progress_bar\n# from torchinfo import summary\n\nwarnings.filterwarnings('ignore')\npd.set_option(\"display.max_columns\", 25)\npd.set_option('display.max_rows', 20)\n# %load_ext line_profiler","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Configuration","metadata":{}},{"cell_type":"code","source":"config = {\n    'batch_size': 4,\n    'seed': 46,\n    'num_classes': 4,\n    'fold': 5,\n    'image_size': 512,\n    'num_workers': 4\n}","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Seed","metadata":{}},{"cell_type":"code","source":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\n    \nseed_everything(config['seed'])","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Path","metadata":{}},{"cell_type":"code","source":"SAMP_SUB = '../input/siim-covid19-detection/sample_submission.csv'\nTRAIN_IMAGE_LEVEL = '../input/siim-covid19-detection/train_image_level.csv'\nTRAIN_STUDY_LEVEL = '../input/siim-covid19-detection/train_study_level.csv'\nTRAIN_PATH = '../input/siim-covid19-detection/train'\nTEST_PATH = '../input/siim-covid19-detection/test'\nTDF_PATH = '../input/siim-train-df/train_df.csv'\n\nTRAIN_DFV2 = '../input/siim-train-df/train_df_v2.csv'\nTRAIN_PNG = '../input/siim-covid19-resized-to-512px-png/train'","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Setup DataFrame","metadata":{}},{"cell_type":"code","source":"train_df = pd.read_csv(TDF_PATH)\nstudy_lvl = pd.read_csv(TRAIN_STUDY_LEVEL)\nimage_lvl = pd.read_csv(TRAIN_IMAGE_LEVEL)\n\ntrain_df['integer_label'] = np.argmax(train_df.iloc[:,4:8].values, axis=1)\ntrain_df['ImageInstanceUID'] = train_df['id'].str.split('_').apply(lambda row: row[0])\ntrain_df['train_png'] = glob(f'{TRAIN_PNG}/*')\n\nbboxes_list = []\nfor bbox in train_df['boxes']:\n    temp = []\n    for i in range(10):\n        try:\n            box = ast.literal_eval(bbox)[i]\n            # pascal\n#             x_min = box['x']\n#             y_min = box['y']\n#             x_max = box['x'] + box['width']\n#             y_max = box['y'] + box['height']\n            \n            # coco \n            x_min = box['x']\n            y_min = box['y']\n            x_max = box['width']\n            y_max = box['height']\n            \n            box_pascal = [x_min, y_min, x_max, y_max]\n            temp.append(box_pascal)\n        except IndexError:\n            pass\n        except ValueError:\n            temp.append(np.nan)\n            \n    if np.isnan(temp).all():\n        temp = [[0.0, 0.0, 1.0, 1.0]]\n\n    bboxes_list.append(temp)\n\nbboxes_df = pd.DataFrame(bboxes_list, columns=[f'box_{i}' for i in range(8)])\ntrain_df = pd.concat([train_df, bboxes_df], axis=1)\n\n# drop weird data \n# not negative and no bbox\n\nnot_zeros_df = train_df[train_df['integer_label'] != 0]\ndrop_row = not_zeros_df[not_zeros_df['boxes'].isnull()].index.values\ntrain_df = train_df.drop(drop_row)\ntrain_df = train_df.reset_index(drop=True)\ntrain_df.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split","metadata":{}},{"cell_type":"code","source":"skf = StratifiedKFold(config['fold'], shuffle=True, random_state=config['seed'])\nfolds_df = train_df.copy()\n\nfor f, (train_idx, valid_idx) in enumerate(skf.split(X=folds_df.index.values, y=folds_df.integer_label.values)):\n    folds_df.loc[folds_df.iloc[valid_idx].index, 'fold'] = f\n\nfolds_df['fold'] = folds_df['fold'].astype(np.int)\nfolds_df.groupby(['fold', folds_df.integer_label]).size()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def dicom2array(path, voi_lut=True, fix_monochrome=True): # dicom\n    dicom = pydicom.dcmread(path)\n    # VOI LUT (if available by DICOM device) is used to\n    # transform raw DICOM data to \"human-friendly\" view\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n    # depending on this value, X-ray may look inverted - fix that:\n    if fix_monochrome and dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data / np.max(data)\n    data = (data * 255).astype(np.uint8)\n    return data\n\ndef normalize_image(image):\n    image_max = image.max().item()\n    image_min = image.min().item()\n    image_norm = (image - image_min) / (image_max - image_min)\n    return image_norm","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for i, row in train_df[[f'box_{i}' for i in range(8)] + ['integer_label']].iterrows():\n    bboxes = row.dropna()[:-1].values\n    labels = row.dropna()[-1]\n    labels = np.full(len(bboxes), labels)\n#     print(labels)\n    for bbox, label in zip(bboxes, labels):\n        test_dict = dict(bboxes=bbox,\n                         labels=label)\n    break","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def create_anno_file(df):\n    data_infos = []\n    image_list = df['path_png'].tolist()\n    \n    for image_path in image_list:\n        filename = image_path\n        height = config['image_size']\n        width = config['image_size']\n        \n        data_info = dict(filename=filename,\n                         width=width,\n                         height=height,\n                         ann=[])\n        \n        bboxes_df = df[[f'box_{i}' for i in range(8)] + ['integer_label']]\n        \n        for idx, row in bboxes_df.itterrows():\n            bboxes = row.dropna()[:-1].values\n            labels = row.dropna()[-1]\n            labels = np.full(len(bboxes), labels)\n            for bbox, label in zip(bboxes, labels):\n                anno_dict = dict(bboxes=np.array(bbox),\n                                 labels=np.array(label))\n                \n            data_info['ann'].append(anno_dict)\n        data_infos.append(data_info)\n    return data_infos","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import mmcv\nfrom mmdet.datasets.builder import DATASETS\nfrom mmdet.datasets.custom import CustomDataset\nfrom mmcv import Config\n\n@DATASETS.register_module()\nclass SiimDatset(CustomDataset)\n    CLASSES = ()\n    \n    def load_annotions(self, df):\n        data_infos = []\n        image_list = df['path_png'].tolist()\n\n        for image_path in image_list:\n            filename = image_path\n            height = config['image_size']\n            width = config['image_size']\n\n            data_info = dict(filename=filename,\n                             width=width,\n                             height=height,\n                             ann=[])\n\n            bboxes_df = df[[f'box_{i}' for i in range(8)] + ['integer_label']]\n\n            for idx, row in bboxes_df.itterrows():\n                bboxes = row.dropna()[:-1].values\n                labels = row.dropna()[-1]\n                labels = np.full(len(bboxes), labels)\n                for bbox, label in zip(bboxes, labels):\n                    anno_dict = dict(bboxes=np.array(bbox),\n                                     labels=np.array(label))\n\n                data_info['ann'].append(anno_dict)\n            data_infos.append(data_info)\n        return data_infos","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#\n# [\n#     {\n#         'filename': 'a.jpg',\n#         'width': 1280,\n#         'height': 720,\n#         'ann': {\n#             'bboxes': <np.ndarray> (n, 4),\n#             'labels': <np.ndarray> (n, ),\n#             'bboxes_ignore': <np.ndarray> (k, 4), (optional field)\n#             'labels_ignore': <np.ndarray> (k, 4) (optional field)\n#         }\n#     },\n#     ...\n# ]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg = Config.fromfile()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"cfg.dataset_type = 'SiimDataset'\n# cfg.dataroot = ''\ncfg.data.test.type\ncfg.data.test.data_root\ncfg.data.test.ann_file\ncfg.data.test.img_prefix\n\ncfg.data.train.type\ncfg.data.train.data_root\ncfg.data.train.ann_file\ncfg.data.train.img_prefix\n\ncfg.data.val.type\ncfg.data.val.data_root\ncfg.data.val.ann_file\ncfg.data.val.img_prefix\n\ncfg.model.roi_head.bbox_head.num_claases = 4\n# cfg.load_from = ''\ncfg.word_dir = './'\n\ncfg.optimizer.lr = 0.02 / 8\ncfg.lr_config.warmup = None\ncfg.log_config.interval = 5\n\ncfg.evaluation.metric = 'mAP'\ncfg.evaluation.interval = 5\ncfg.checkpoint_config.interval = 5\n\ncfg.seed = config['seed']\n\nmmdet.apis.set_random_seed(config['seed'], deterministic=False)\ncfg.gpu_ids = range(1)\n\nprint(f'Config:\\n{cfg.pretty_text}')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from mmdet.datasets import build_dataset\nfrom mmdet.models import build_detector\nfrom mmdet.apis import train_detector\n\ndataset = [build_dataset(cfg.data.train)]\n\nmodel = build_detector(cfg.model,\n                       train_cfg=cfg.get('train_cfg'),\n                       test_cfg=cfg.get('test_cfg'))\nmodel.CLASSES = datasets[0].CLASSES\n\nmcv.mkdir_or_exist(osp.abspath(cfg.work_dir))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_detector(model, datasets, cfg, distributed=False, validate=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"img = mmcv.imread('kitti_tiny/training/image_2/000068.jpeg')\n\nmodel.cfg = cfg\nresult = inference_detector(model, img)\nshow_result_pyplot(model, img, result)","metadata":{},"execution_count":null,"outputs":[]}]}